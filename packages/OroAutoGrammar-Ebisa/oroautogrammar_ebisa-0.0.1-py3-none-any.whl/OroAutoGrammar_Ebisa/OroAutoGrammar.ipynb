{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNybCpL21MxH/qaJY1gm19M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["----------------------------\n","@Author: Ebisa A. Gemechu\n","January 2023\n","----------------------------\n","**Project Description:**\n","\n","This is a novel python package that recieves an Oromo text file from a user; extract every possible root-verbs from the text; and stores them into a python list. It then trims all the verbs in the list to form their corresponding list of stems. Finally, the algorithm builds the corresponding phrases using an appropriate affixation and pronouns.The generated phrases can indicate sentence elements like, number, gender and cases."],"metadata":{"id":"MYNGINlYEYvn"}},{"cell_type":"code","source":["\"\"\" \n","  A Python package for generating grammar aware Oromo phrases from a given raw text.\n","\n","\tInput          : any Oromo document file saved as a .txt in a directory    \n","\n","\tAttributes:\n","\t\tin_filename  : Oromo document file saved as a .txt file\n","    OroStopWprds : All posible list of Oromo words in a given text, that has no significant\n","                   value for word formation.\n","    root_ve      : is a variable that stores the list of extracted words\n","\t\tverb         : is a temporary variable to iterate over the list of root verbs\n","\t\tStem         : is a variable that stores the list of trimmed stems from each corresponding root words\n","\n","  Output         : A csv file that contains a grammar-based dataset of the generated Oromp phrases \n","\t\t\t\n","\"\"\""],"metadata":{"id":"3YUwwZhJAQEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZRhSRj7p_lz","executionInfo":{"status":"ok","timestamp":1675068925604,"user_tz":-330,"elapsed":31915,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}},"outputId":"65db82fe-2264-4b3a-c7b3-2b527825de79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# Import the required packages\n","import string\n","\n","import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lerMlxPzzeTY","executionInfo":{"status":"ok","timestamp":1675068927933,"user_tz":-330,"elapsed":2346,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}},"outputId":"d0c82f7e-bbf2-4776-c68c-57602c3935f6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text"],"metadata":{"id":"L6LRBJszqeZM","executionInfo":{"status":"ok","timestamp":1675068927934,"user_tz":-330,"elapsed":47,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# replace '--' with a space ' '\n","\tdoc = doc.replace('--', ' ')\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', string.punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\t#tokens = [word for word in tokens if word.isalpha()]\n","\t# change to make lower case\n","\ttokens = [word.lower() for word in tokens]\n","\treturn tokens"],"metadata":{"id":"_2_PxhPyqgPt","executionInfo":{"status":"ok","timestamp":1675068927936,"user_tz":-330,"elapsed":45,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# save tokens to file, one dialog per line\n","def save_doc(lines, filename):\n","\tdata = '\\n'.join(lines)\n","\tfile = open(filename, 'w')\n","\tfile.write(data)\n","\tfile.close()"],"metadata":{"id":"27g-5tQfqlrM","executionInfo":{"status":"ok","timestamp":1675068927938,"user_tz":-330,"elapsed":32,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Accept Input from user\n","import sys\n","import os\n","\n","# Accept a raw document from user with a complete file path\n","in_filename = input(\"Enter the complete path of Oromo text as a.txt or.csv file and press enter_key: \")\n","doc = load_doc(in_filename)\n","#Check if the file is entered file by the user is correctly aploaded \n","assert os.path.exists(in_filename), \"I did not find the file at,\" + (in_filename)\n","print(\"Bonza we found your file!\")\n","\n","print(\"Sample Tokens:/n\" + doc[:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZrMh1_y2TGu","executionInfo":{"status":"ok","timestamp":1675068934344,"user_tz":-330,"elapsed":6434,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}},"outputId":"db595c73-0f47-44cf-a732-dc622856a542"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the complete path of Oromo text as a.txt or.csv file and press enter_key: /content/gdrive/MyDrive/OroAutoGrammar/oro_text.txt\n","Bonza we found your file!\n","Sample Tokens:/nï»¿Jidduu kana hariiroo mootummaafi amantii jidduu jiru irratti falmiin godhamaa jira. Anis gama kooti\n"]}]},{"cell_type":"code","source":["# Call the function 'clean_doc' and asign it to a variable 'word_ext'\n","word_ext=  clean_doc(doc)"],"metadata":{"id":"z7c5R-MR2vB3","executionInfo":{"status":"ok","timestamp":1675068934346,"user_tz":-330,"elapsed":53,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Declare the necessary variables and asign values\n","oro_Vowels=   ['a','e','i','o','u']\n","verb_suffix = ['u','uu', 'uun','amu','e','ne','te','tan','an'] \n","\n","OroStopWprds= ['ani','ana','anaaf', 'kankoo','kan', 'koo','kiyya','kankiyya','anuma', 'numa','nuti','nuyi','nu','nuyiif','keenya','kankeenya',\n","               'keenyuma','kanumakeenya','qabu','qabna','ati','siif','kankee','kee','sihuma',\"si'uma\",'sima','isiniif','keessan','kankeessan',\n","               'isin','isuma','kanisaa','isuma','niqabdu','niqabaattu', 'niqabdan','qabdu','qabaattu','qabdan','ishee','isheedhaaf''isheef',\n","               'ishii','isinuma','isa','isaaf','kansaa','kanisaa','ishee','ishii','ishiif','isheedhaaf','kanishee','kanishii','isheema',\n","               'isheeen','wanta','wantoo','wantoota','wantoon','waan','kun','waankun','waantittiin','waantichi','waantichaaf','wantittiif',\n","               'waantittiima','waantichuma','waansaa','waanuma','isaan','keessan','isaaniif','isaanii','kanisaanii','isaanuma','isaanumaaf',\n","               'akkasi','akkana','akkanuma','akkasuma','akkasiim','maal',\"waa'ee\",'kam','eenyu','eenyuuf','eenyuuf','eenyuudhaaf','kana','sana',\n","               \"ta'innaa\",'laata','laata','akkasii', 'akkas','kanneen','kunniin','kkf','faan','ture','a', 'an','jira','jiraanna','qabna',\n","               'qabaannaa','raawwii', 'raawwataa','itti','fi','f', 'garuu','tarii','ni','san','sana','sanaan','saniin','yookin','yookiin',\n","               'yookis','kanaaf','kanaafuu','maaliifuu','akkuma','akkasuma','akkasumatti','akkasumaan','akkanumatti','akka','akkamalee',\n","               'garamalee','garmalee','akkamitti','akkamittiin','akkanattin','ammasitti','agasitti','agasittuu','oggasitti','oggasittuu',\n","               'agas','agasitti','agasmara','yoomillee','yoomiyyuu','illee','utuu','osoo','itti','ittiin','ittuma','ittidhiisi','ittidhiisaa',\n","               'dha','dhaam','wajjin','wajjinumaan','waliin','walumaan','walumatti','walumaa','walumaagalatti','dimshaashumatti',\"waa'ee\",\n","               'faallaa','dagla','gidduu','karaa','yeroo','duratti','boodatti','booda','irra','biidarra','jala','irraa','jalaa','ol','olii',\n","               'gadi','gara','as','asi','asii','asiif','achi','achiin','achitti','irraan','achirraan','keessa','keessatti','ala','bukkee',\n","               'cina','bira','biraan','bani','cufi','gararraa','gajjallaa','goda','goodaa','daka', 'amma','ammas','dabalataan','darbee',\n","               'yoom','eessa', 'maaliif','akkamitti','hunda','kamiyyuu','lachanuu',\"tokkoon_tokkoon\",'xiqqoo','tana','kana','gara','garam',\n","               'garas','garana','hundacaalaa','irracaalaa','caalaa','kanbiraa','biraa','muraasa','kanakka','akka',\"waa'uu\",'waahuu','waayyuu',\n","               'omaa','homaa','yookin','yookis','eeyyee','miti','lakki','lakkii','qofa','dhuunfaa','kanaaf','akkasuma','akkasumas','baayyee',\n","               \"baa'ee\",\"danda'a\",\"ta'a\",\"ta'uu\",'mala','reefa','hin','ni', \"ta'uuqaba\", 'qaba', \"nita'a\",\"ta'innaa\",'tokko',\"si'a\",'altokko', \n","               \"si'atokko\",\"hinta'u\",\"hintaane\", \"hindanda'amne\",\"hinraawwatamne\",'hinbarbaachifne','hinmilkoofne','hindagatamne','jirti',\n","               'jiru','jiran','dachaa','gaara','tabba','oduu','yoo','beenu','beenuu','beenaa','deemi','deemaa','yoona','yoonan','yommuu',\n","               'yommuun','yammuu','yammuun','yammuttii','ibsaniiru','dhiyaannu','dhaggeeffadhaa','eenyutu','eenyuun','eenyufaa','eenyuufaa',\n","               'eenyufaatu','fageenyan','fageenyaan','barraaye','barruu','barruun','barraaye','dabsineetu','deemame','dhageenyu','dhageenye',\n","               'fullaate','gufuu','guyyuu','hoggayyuu','haatahu','haatayu',\"haata'u\",'haatahuyyuu','haatayuyyuu',\"haata'uyyuu\",'hundaatiifu',\n","               'mootummaatitu','hinmalle','hinmalletu','halle','malle','heddu','hedduu','hedduun','hedduutu','hundaatuu','hundaattuu',\n","               'hundaatiifuu','hundaatuu','hundaafuu','takkaahuu','takkaiyyuu','seenaniiru','hundinuu','martinuu','inumaatuu','inumaatuu', \n","               'kamiituu','keessattu','keessattuu','lachuu','loontu','lubbuu',\"murtaa'e\",'murtaae','taane','taate','rabsaman','tiruun',\n","               'tokkoon','lamaam','lamman','sadan','arfan','afran','shanan',\"ja'an\",'torban','saddettan','saddeettan','salgan','saglan',\n","               'kurnan','digdaman','soddoman','afurtaman','shantaman','jaataman','torbaataman','seddettaman','sagaltaman','dhibba','kuma',  \n","               'kitila','miliyoona','jabana','weedduu','weedduun','xiyyeeffame','jidduu','gidduu','jirtu','jiru','jiruu','jiran','jiruun',\n","               'jidduu','barbaachuu']\n","\n","# Iterate over the list of words and extract root verbs from the given text file\n","def root_verb(word_ext):\n","  next_verb = []\n","  for verb in word_ext:\n","    if verb not in OroStopWprds:\n","      [next_verb.append(verb) for saffix in verb_suffix if(verb[-4:] == saffix or verb[-3:] == saffix or verb[-2:] == saffix or \n","      verb[-1:] == saffix)]\n","  return next_verb"],"metadata":{"id":"bkZF2MJQQwLv","executionInfo":{"status":"ok","timestamp":1675068934348,"user_tz":-330,"elapsed":51,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Extract unique root verbs into array list\n","root_ve= root_verb(word_ext)\n","\n","import numpy as np  \n","root_ve = list(np.unique(root_ve))\n","print(root_ve[:10])"],"metadata":{"id":"QwYUHo24QxCT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068934350,"user_tz":-330,"elapsed":51,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}},"outputId":"f3693c05-aafe-45f9-b536-25a8fab76715"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['aadaan', 'abbummaan', 'abdachiisaan', 'addaan', 'addeessan', 'addunyaan', 'afaan', 'afeeruu', 'aguugan', 'amantee']\n"]}]},{"cell_type":"code","source":["# import a csv module\n","import csv\n","\"\"\"\n","Create a .csv file called 'oro_generated_grammar.csv' in the directory '/content/gdrive/MyDrive/'\n","and write fieldname headers in the created excel file.\n","\"\"\"\n","with open('/content/gdrive/MyDrive/oro_generated_grammar.csv', 'w', newline='') as csvfile:\n","    fieldnames = ['Hundee |Root|', 'Jirma |Stem|','Ani |I|','Nuti |We|','Ati |You|','Isin |You|','Inni |He|','Isheen |She|','Isaan |They|']\n","    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","    writer.writeheader()\n","\n","    # Iterate over the list of the root verbs\n","    for verb in root_ve:\n","\n","      # If the verb contains noun or adjective affixes, then move next\n","      if((verb[-2:] in ['aa','ee','ii','oo']) or verb[-3:] =='aan'or verb[:3] =='aa'or verb[-4:-1] =='aa' or verb[-4:] == 'dduu'\n","         or verb[-3:] =='lee'or verb[-4:] =='wwan' or verb[-7:-2] =='ummaa' or verb[-4:] == 'maan' or verb[-6:] =='ummaan'): \n","        continue\n","\n","      # Ckeck all possible conditions to trim the verbs into their stems and do the re-affixation\n","      elif(len(verb) > 4 and (verb[2:4] in ['ch','nn','tt'] and verb[2] != verb[3] )): \n","        stem= (verb[:2] + 'dh')\n","      elif(len(verb) > 5 and verb[-5:-3] =='ch' and verb[-3] !='i' and verb[2] !='l'):  \n","        stem= (verb[:-5] + 't')\n","      elif(len(verb) > 4 and ( verb[-5] != 'l') and verb[-4:-2] =='ch'):  \n","        stem= (verb[:-4] + 't')\n","      elif(len(verb) > 5 and verb[-5:-1] =='eeny'):  \n","        stem= (verb[:-5] + \"a'\")\n","      elif(len(verb) > 6 and (verb[-4:-2] in ['dh','ny'] or verb[-3:-1] in ['dh','ny'] )):  \n","        stem= (verb[:-3] + 't')\n","      elif(len(verb) > 5 and verb[-5:-2] =='sif'):  \n","        stem= (verb[:-3] + 's') \n","      elif(len(verb) > 5 and (verb[-5:-3] =='ft' or verb[-4:-2] =='ft') ):   \n","        stem= (verb[:-5] + 's')  \n","      elif(len(verb) > 4 and verb[-4:] in ['maan','uutu']  and verb[-5] != verb[-4]):   \n","        stem= verb[:-4]\n","      elif(verb[-4:] in ['anne','annu']):    \n","        stem= (verb[:-3] + 't')\n","      elif( len(verb) > 3 and verb[-3:] in ['uun','utu','tuu'] ): #'ine',  \n","        stem= verb[:-3] \n","      elif(verb[-4:] =='ssan'):    \n","        stem= verb[:-2]\n","      elif(verb[-3:] in ['ame','ate']):    \n","        stem= verb[:-1]\n","      elif(len(verb) > 3 and (verb[-3] in oro_Vowels) and verb[-2:] == 'te'):     \n","        stem= verb[:-1]  \n","      elif (len(verb) > 3 and verb[-2:] in ['uu','ne','te','an']): \n","        stem= verb[:-2] \n","      elif(len(verb) > 3 and (verb[-3] not in oro_Vowels) and (verb[-2:] in ['du','nu','re','tu'])): #and verb[2] != verb[3]    \n","        stem= verb[:-2] \n","      else:\n","        stem= verb[:-1]\n","\n","      # write the re-synthesized verbs into the created excel file \n","      writer.writerow({'Hundee |Root|': verb, 'Jirma |Stem|':stem +'_' ,'Ani |I|': 'Ani '+ stem + 'e', 'Nuti |We|': 'Nuti '+ stem + 'ne',\n","                       'Ati |You|': 'Ati '+ stem +'te','Isin |You|':'Isin '+ stem + 'tan', 'Inni |He|': 'Inni '+ stem + 'e', 'Isheen |She|':\n","                       'Isheen '+ stem + 'te', 'Isaan |They|': 'Isaan '+ stem + 'an'})"],"metadata":{"id":"ncdC_icsQ1QB","executionInfo":{"status":"ok","timestamp":1675068934351,"user_tz":-330,"elapsed":26,"user":{"displayName":"EBISA A. GEMECHU","userId":"01594227837107547769"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["/content/gdrive/MyDrive/OroAutoGrammar/oro_text.txt"],"metadata":{"id":"e0z3ON9707Mi"}}]}