import random

import numpy as np
import torch
from torch import nn
from torch.nn.utils import rnn

from .base import BaseCollateFn
from .base import BaseModule
from .base import TimeSeriesEstimator
from .datasets import TimeseriesDataset


class Seq2Seq(TimeSeriesEstimator):
    """SeqToSeq architecture with additional Embedding layer.

    This model applies a sequence to sequence learning architecture to solve
    the multivariate multistep time series forecasting problem. The additional
    embedding layer allows to condition the encoder module on
    time independent/static categorical data, making it possible to learn and
    predict multiple time series using a single model (i.e. a single non linear
    mapping).

    Parameters
    ----------
    group_ids : list of str
        List of column names identifying a time series. This means that the
        ``group_ids`` identify a sample together with the ``date``. If you
        have only one times series, set this to the name of column that is
        constant.

    time_idx : str
        Time index column. This column is used to determine the sequence of
        samples.

    target : str
        Target column. Column containing the values to be predicted.

    max_prediction_length : int
        Maximum prediction/decoder length. Usually this this is defined by
        the difference between forecasting dates.

    max_encoder_length : int
        Maximum length to encode. This is the maximum history length used by
        the time series dataset.

    time_varying_known_reals : list of str
        List of continuous variables that change over time and are known in the
        future (e.g. price of a product, but not demand of a product). If None,
        every numeric column excluding ``target`` is used.

    time_varying_unknown_reals : list of str
        List of continuous variables that change over time and are not known in
        the future. You might want to include your ``target`` here. If None,
        only ``target`` is used.

    static_categoricals : list of str
        List of categorical variables that do not change over time (also known
        as `time independent variables`). You might want to include your
        ``group_ids`` here for the learning algorithm to distinguish between
        different time series. If None, only ``group_ids`` is used.

    min_encoder_length : int, default=None
        Minimum allowed length to encode. If None, defaults to
        ``max_encoder_length``.

    criterion : class, default=None
        The uninitialized criterion (loss) used to optimize the module. If
        None, the :class:`.RMSE` (root mean squared error) is used.

    optimizer : class, default=None
        The uninitialized optimizer (update rule) used to optimize the
        module. if None, :class:`.Adam` optimizer is used.

    lr : float, default=1e-5
        Learning rate passed to the optimizer.

    max_epochs : int, default=10
        The number of epochs to train for each :meth:`fit` call. Note that you
        may keyboard-interrupt training at any time.

    batch_size : int, default=64
        Mini-batch size. If ``batch_size`` is -1, a single batch with all the
        data will be used during training and validation.

    callbacks: None, “disable”, or list of Callback instances, default=None
        Which callbacks to enable.

        - If callbacks=None, only use default callbacks which include:
            - `epoch_timer`: measures the duration of each epoch
            - `train_loss`: computes average of train batch losses
            - `valid_loss`: computes average of valid batch losses
            - `print_log`:  prints all of the above in nice format

        - If callbacks="disable":
            disable all callbacks, i.e. do not run any of the callbacks.

        - If callbacks is a list of callbacks:
            use those callbacks in addition to the default callbacks. Each
            callback should be an instance of skorch :class:`.Callback`.

    warm_start: bool, default=False
        Whether each fit call should lead to a re-initialization of the module
        (cold start) or whether the module should be trained further
        (warm start).

    emb_dim : int, default=10
        Dimension of every embedding table

    hidden_size : int, default=16
        Size of the context vector

    tf_ratio : float, default=0.2
        For every forward pass, if the sampling from a standard uniform
        distribution is less than ``tf_ratio``, teacher forcing is used.

    cell_type : str, {'lstm', 'gru}, default='lstm'
        Recurrent unit to be used for both encoder and decoder

    verbose : int, default=1
        This parameter controls how much print output is generated by
        the net and its callbacks. By setting this value to 0, e.g. the
        summary scores at the end of each epoch are no longer printed.
        This can be useful when running a hyperparameter search. The
        summary scores are always logged in the history attribute,
        regardless of the verbose setting.

    device : str, torch.device, default="cpu"
        The compute device to be used. If set to "cuda", data in torch
        tensors will be pushed to cuda tensors before being sent to the
        module. If set to None, then all compute devices will be left
        unmodified.

    kwargs : dict
       Extra prefixed parameters (see list of supported prefixes with
       self.prefixes).
    """

    def __init__(self, group_ids, time_idx, target, max_prediction_length,
                 max_encoder_length, time_varying_known_reals,
                 time_varying_unknown_reals, static_categoricals,
                 cv_split=None, min_encoder_length=None, criterion=None,
                 optimizer=None, lr=1e-5, max_epochs=10, batch_size=64,
                 callbacks=None, warm_start=False, emb_dim=10, hidden_size=16,
                 tf_ratio=0.2, cell_type='lstm', num_layers=1, verbose=1,
                 device='cpu', **kwargs):
        super().__init__(
            module=Seq2SeqModule, dataset=TimeseriesDataset,
            group_ids=group_ids, time_idx=time_idx, target=target,
            max_prediction_length=max_prediction_length,
            time_varying_known_reals=time_varying_known_reals,
            time_varying_unknown_reals=time_varying_unknown_reals,
            static_categoricals=static_categoricals, cv_split=cv_split,
            max_encoder_length=max_encoder_length,
            min_encoder_length=min_encoder_length,
            max_epochs=max_epochs, lr=lr, batch_size=batch_size,
            optimizer=optimizer, criterion=criterion, callbacks=callbacks,
            warm_start=warm_start, verbose=verbose, device=device, **kwargs
        )
        self.emb_dim = emb_dim
        self.hidden_size = hidden_size
        self.tf_ratio = tf_ratio
        self.cell_type = cell_type
        self.num_layers = num_layers
        self._collate_fn = Seq2SeqCollateFn
        self._output_decoder = Seq2SeqOutputDecoder


class Seq2SeqCollateFn(BaseCollateFn):

    def __init__(self, dataset):
        super().__init__(dataset)

    def __call__(self, batch):
        n_unknown = len(self.dataset.time_varying_unknown_reals)
        batch_size = len(batch)
        emb_x = torch.zeros(batch_size, 1,
                            dtype=torch.int)  # Pre-allocate memory.
        enc_lens = []
        enc_x = []
        dec_x = []
        target = []

        for i, (X, y) in enumerate(batch):
            enc_len = X['encoder_length']
            dec_len = X['decoder_length']
            enc_lens.append(enc_len)

            emb_x[i] = X['x_cat'][0]
            enc_x.append(X['x_cont'][:enc_len, :])
            dec_x.append(X['x_cont'][-dec_len:, :-n_unknown])
            target.append(y[0])

        enc_x = self.pad_sequence(enc_x)
        dec_x = torch.stack(dec_x)
        target = torch.stack(target)

        return {
                   'emb_x': emb_x,
                   'enc_x': enc_x,
                   'dec_x': dec_x,
                   'dec_y': target,
                   'enc_lens': enc_lens
               }, target

    def pad_sequence(self, sequence, batch_first=True):
        return rnn.pad_sequence(sequence, batch_first=batch_first)


class Seq2SeqOutputDecoder:
    """Output decoder for encoder-decoder architectures.

    Removes sliding window format.

    Parameters
    ----------
    dataset : SeqToSeqDataset or PytorchForecastingDataset
    """

    def __init__(self, dataset):
        self.dataset = dataset

    def decode(self, prediction, out=None):
        """Decodes predictions.

        Parameters
        ----------
        prediction : array_like
            Raw prediction.

        out : pd.DataFrame, default=None
            If provided, the destination to place the result. The shape must be
            correct, matching that of what decode would have returned if no out
            argument were specified.
        """
        groupby = self.dataset.decoded_index.groupby(self.dataset.group_ids)
        sequence_len = self.dataset.max_prediction_length
        decoded_prediction = []

        for i, group_id in enumerate(groupby.groups):
            group = groupby.get_group(group_id)
            index = group.index[::sequence_len].tolist()
            group_prediction = prediction[index].flatten()

            # Get number of remaining sequences.
            mod = (len(group) - 1) % sequence_len
            if mod > 0:
                # Get the last element of each of the last `mod` sequences.
                mod_sequence = prediction[-mod:, -1]
                group_prediction = np.concatenate(
                    (group_prediction, mod_sequence)
                )
            decoded_prediction.append(group_prediction)

        decoded_prediction = np.concatenate(decoded_prediction)

        if out is None:
            return decoded_prediction

        return self._insert_in_X(out, decoded_prediction, list(groupby.groups))

    def _insert_in_X(self, X, decoded_prediction, groups_order):
        # Retrieve settings from ``dataset``.
        encoder_length = self.dataset.max_encoder_length
        group_ids = self.dataset.group_ids

        # Drop first ``max_encoder_length`` rows from each group.
        X = X.drop(X.groupby(group_ids).head(encoder_length).index)

        # Loc in given order.
        X = X.set_index(group_ids).loc[groups_order].reset_index()

        X[self.dataset.target] = decoded_prediction
        return X


class Seq2SeqModule(BaseModule):
    """PyTorch model for the encoder-decoder architecture.

    This model is equipped with an additional embedding layer for conditioning
    the Encoder unit with time independent features.

    Parameters
    ----------
    emb_dim : int
        Dimension for every embedding table.

    emb_sizes : tuple
        Size of each embedding table. For example, if two static categorical
        features are to be included to the model and they have `n` and `m`
        unique elements, respectively, then ``emb_sizes`` must equal `(n, m)`.
        The dimension of each embedding table is given by the ``emb_dim``
        param.

    enc_size : int
        Encoder size. Number of features to be included in the encoder module

    dec_size : int
        Decoder size. Number of feature to be included in the decoder module

    hidden_size : int
        Size of the context vector

    tf_ratio : float, default=0.2
        For every forward pass, if the sampling from a standard uniform
        distribution is less than ``tf_ratio``, teacher forcing ratio will be
        used.

    cell_type : str, {'lstm', 'gru}, default='lstm'
    """

    def __init__(self, emb_dim, emb_sizes, enc_size, dec_size, hidden_size,
                 tf_ratio=0.2, cell_type='lstm', num_layers=1):
        super().__init__()
        self.embedding = Embedding(emb_sizes, emb_dim, hidden_size, num_layers)
        self.encoder = Encoder(enc_size, hidden_size, cell_type, num_layers)
        self.decoder = Decoder(dec_size, hidden_size, tf_ratio, cell_type,
                               num_layers)

    def forward(self, emb_x, enc_x, dec_x, dec_y, enc_lens):
        enc_state = self.embedding(emb_x)
        enc_out, enc_state = self.encoder(enc_x, enc_lens, h_0=enc_state)
        dec_state = enc_state  # Decoders state is last encoders state
        return self.decoder(dec_x, dec_state, enc_out, dec_y)

    @classmethod
    def from_dataset(cls, dataset, **kwargs):
        """Create model from dataset.

        Parameters
        ----------
        dataset : MasterDataset object
            dataset object from which init parameters will be obtained

        kwargs : keyword arguments
            additional arguments such as hyperparameters for model
            (see ``__init__()``)

        Returns
        -------
        SeqToSeqModule object
        """
        emb_sizes = tuple(
            torch.max(dataset.data['categoricals'], dim=0).values.numpy() + 1
        )
        enc_size = len(
            dataset.time_varying_known_reals +
            dataset.time_varying_unknown_reals
        )
        dec_size = len(dataset.time_varying_known_reals) + 1
        init_kwargs = dict(
            emb_sizes=emb_sizes, enc_size=enc_size, dec_size=dec_size
        )
        init_kwargs.update(**kwargs)
        return cls(**init_kwargs)


class Embedding(nn.Module):
    """Embedding layers for conditioning the encoder with time
    independents/static categorical variables.
    """

    def __init__(self, emb_sizes, emb_dim, hidden_size, num_layers):
        super().__init__()
        self.emb_sizes = emb_sizes
        self.emb_dim = emb_dim
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        emb_trans = {}
        linear_trans = {}
        self.linear = nn.Linear(hidden_size, len(emb_sizes), 1)
        for i, size in enumerate(emb_sizes):
            # Each column will have its own embedding and linear
            # transformation. The order will be kept through dictionaries.
            emb_trans[str(i)] = nn.Embedding(size, emb_dim)
            linear_trans[str(i)] = nn.Linear(emb_dim, hidden_size * num_layers)
        self.emb_trans = nn.ModuleDict(emb_trans)
        self.linear_trans = nn.ModuleDict(linear_trans)

    def forward(self, tokens):
        batch_size = tokens.shape[0]

        # ``dense_conditionals`` concatenates all static (time independent)
        # conditions after they have been embedded and linearly transformed.
        output_shape = (
            batch_size,
            self.hidden_size,
            self.num_layers,
            len(self.emb_sizes)
        )
        dense_conditionals = torch.zeros(output_shape, device=tokens.device)

        for i, col in enumerate(self.emb_trans):
            column_tokens = tokens[:, [i]]
            emb_column = self.emb_trans[col](column_tokens)
            dense_column = self.linear_trans[col](emb_column)
            dense_conditionals[:, :, :, i] = torch.reshape(
                dense_column.squeeze(dim=1),
                (batch_size, self.hidden_size, self.num_layers)
            )

        if len(self.emb_sizes) > 1:
            output = self.linear(dense_conditionals)
        else:
            output = dense_conditionals

        output = output.squeeze(dim=-1).permute(2, 0, 1)
        return output


class Encoder(nn.Module):
    """Encoder module
    """

    def __init__(self, input_size, hidden_size, cell_type, num_layers):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.cell_type = cell_type
        self.num_layers = num_layers
        self.cell_unit = _make_rnn(self)

    def forward(self, input, enc_lens, h_0=None):
        if self.cell_type == 'lstm':
            h_0 = self._lstm_h_0(h_0)
        input_packed = rnn.pack_padded_sequence(
            input, enc_lens, batch_first=True, enforce_sorted=False
        )
        output_packed, state = self.cell_unit(input_packed, h_0)
        output, _ = rnn.pad_packed_sequence(output_packed, batch_first=True)
        return output, state

    def _lstm_h_0(self, h_0=None):
        """Initializes lstm hidden tensors h_0 and c_0
        """
        if h_0 is None:
            # If the initial hidden state h_0 is None, a None type is returned
            # to trigger the default behaviour for both h_0 and c_0 (both h_0
            # and c_0 default to zero)
            return None
        # Otherwise, h_0 is left untouched and only the initial cell state c_0
        # is set to zero.
        c_0 = torch.zeros_like(h_0, device=h_0.device)
        return h_0, c_0


class Decoder(nn.Module):
    """Decoder module.

    Parameters
    ----------
    input_size : int
        Decoder input size (number of features)

    hidden_size : int
        Size of context vector

    tf_ratio : float
        For each forward pass, if a random sample from a standard uniform
        distribution is less than `tf_ratio`, teacher forcing is used. Use 0
        if teacher forcing is not desired at all.

    cell_type : str, {'lstm', 'gru'}
        Rnn cell for encoder and decoder
    """

    def __init__(self, input_size, hidden_size, tf_ratio, cell_type,
                 num_layers):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.cell_type = cell_type
        self.num_layers = num_layers
        self.cell_unit = _make_rnn(self)
        self.tf_ratio = tf_ratio
        self.linear = nn.Linear(in_features=hidden_size, out_features=1)

    def forward(self, dec_x, state, enc_out, y):
        # Teacher forcing is only available when model.train() is active.
        if self._tf() and self.training:
            return self._tf_forward(y, dec_x, state)
        return self._notf_forward(enc_out, dec_x, state)

    def _tf(self):
        """Sampling from the standard uniform random to decide whether or not
        teacher forcing is used

        Returns
        -------
            - True if a random sample from a standard uniform distribution is
            less than self.tf_ratio.
            - False otherwise.
        """
        tf = True if random.random() < self.tf_ratio else False
        return tf

    def _tf_forward(self, y, dec_x, state):
        """Target values are used as input at every step.

        This is achieved by concatenating the target values in ``y`` and the
        features values in ``dec_x`` in a single input tensor.
        """
        # ``y`` is a tensor of size (batch_size, T) where T is
        # the prediction length and ``dec_x`` is a tensor of size
        # (batch_size, T, F) where F is the number of features. Therefore,
        # an extra dimension is added to ``y`` to perform torch.cat and produce
        # the cell input.
        dec_input = torch.cat((y.unsqueeze(dim=2), dec_x), dim=2)
        dec_output, state = self.cell_unit(dec_input, state)
        dec_output = self.linear(dec_output)
        return dec_output.squeeze(-1)  # squeeze last dim from linear output

    def _notf_forward(self, enc_out, dec_x, state):
        """Output values are used as next input at every step with the first
        input being the last encoder output.
        """
        batch_size = enc_out.shape[0]
        output_length = dec_x.shape[1]
        # First decoder input is the last encoder output
        dec_input_t = enc_out[:, -1:, -1:]
        # decoder_output is a holder for the outputs at every timestep
        dec_output = torch.zeros(
            (batch_size, output_length, 1), device=dec_x.device
        )
        for t in range(output_length):
            future_seqs_t = dec_x[:, [t], :]
            dec_input_t = torch.cat((dec_input_t, future_seqs_t), dim=2)
            dec_output_t, state = self.cell_unit(dec_input_t, state)
            dense_dec_output_t = self.linear(dec_output_t)
            dec_output[:, t, :] = dense_dec_output_t.squeeze(1)
            dec_input_t = dense_dec_output_t.detach()
        return dec_output.squeeze(-1)  # squeeze last dim from linear output


def _make_rnn(module):
    """Private function for selecting between rnn cells.
    """
    rnns = {
        'lstm': nn.LSTM,
        'gru': nn.GRU
    }
    kwargs = {
        'input_size': module.input_size,
        'hidden_size': module.hidden_size,
        'num_layers': module.num_layers,
        'batch_first': True
    }
    return rnns[module.cell_type](**kwargs)
