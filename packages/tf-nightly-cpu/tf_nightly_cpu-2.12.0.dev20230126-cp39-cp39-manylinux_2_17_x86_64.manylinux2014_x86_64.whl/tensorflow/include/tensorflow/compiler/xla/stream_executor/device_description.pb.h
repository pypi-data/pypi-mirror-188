// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/compiler/xla/stream_executor/device_description.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3009000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3009002 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/unknown_field_set.h>
#include "tensorflow/compiler/xla/autotune_results.pb.h"
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto {
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTableField entries[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::AuxillaryParseTableField aux[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTable schema[5]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::FieldMetadata field_metadata[];
  static const ::PROTOBUF_NAMESPACE_ID::internal::SerializationTable serialization_table[];
  static const ::PROTOBUF_NAMESPACE_ID::uint32 offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto;
namespace stream_executor {
class CudaComputeCapabilityProto;
class CudaComputeCapabilityProtoDefaultTypeInternal;
extern CudaComputeCapabilityProtoDefaultTypeInternal _CudaComputeCapabilityProto_default_instance_;
class DnnVersionInfoProto;
class DnnVersionInfoProtoDefaultTypeInternal;
extern DnnVersionInfoProtoDefaultTypeInternal _DnnVersionInfoProto_default_instance_;
class GpuDeviceInfoProto;
class GpuDeviceInfoProtoDefaultTypeInternal;
extern GpuDeviceInfoProtoDefaultTypeInternal _GpuDeviceInfoProto_default_instance_;
class GpuTargetConfigProto;
class GpuTargetConfigProtoDefaultTypeInternal;
extern GpuTargetConfigProtoDefaultTypeInternal _GpuTargetConfigProto_default_instance_;
class RocmComputeCapabilityProto;
class RocmComputeCapabilityProtoDefaultTypeInternal;
extern RocmComputeCapabilityProtoDefaultTypeInternal _RocmComputeCapabilityProto_default_instance_;
}  // namespace stream_executor
PROTOBUF_NAMESPACE_OPEN
template<> ::stream_executor::CudaComputeCapabilityProto* Arena::CreateMaybeMessage<::stream_executor::CudaComputeCapabilityProto>(Arena*);
template<> ::stream_executor::DnnVersionInfoProto* Arena::CreateMaybeMessage<::stream_executor::DnnVersionInfoProto>(Arena*);
template<> ::stream_executor::GpuDeviceInfoProto* Arena::CreateMaybeMessage<::stream_executor::GpuDeviceInfoProto>(Arena*);
template<> ::stream_executor::GpuTargetConfigProto* Arena::CreateMaybeMessage<::stream_executor::GpuTargetConfigProto>(Arena*);
template<> ::stream_executor::RocmComputeCapabilityProto* Arena::CreateMaybeMessage<::stream_executor::RocmComputeCapabilityProto>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace stream_executor {

// ===================================================================

class CudaComputeCapabilityProto :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:stream_executor.CudaComputeCapabilityProto) */ {
 public:
  CudaComputeCapabilityProto();
  virtual ~CudaComputeCapabilityProto();

  CudaComputeCapabilityProto(const CudaComputeCapabilityProto& from);
  CudaComputeCapabilityProto(CudaComputeCapabilityProto&& from) noexcept
    : CudaComputeCapabilityProto() {
    *this = ::std::move(from);
  }

  inline CudaComputeCapabilityProto& operator=(const CudaComputeCapabilityProto& from) {
    CopyFrom(from);
    return *this;
  }
  inline CudaComputeCapabilityProto& operator=(CudaComputeCapabilityProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const CudaComputeCapabilityProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const CudaComputeCapabilityProto* internal_default_instance() {
    return reinterpret_cast<const CudaComputeCapabilityProto*>(
               &_CudaComputeCapabilityProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(CudaComputeCapabilityProto& a, CudaComputeCapabilityProto& b) {
    a.Swap(&b);
  }
  inline void Swap(CudaComputeCapabilityProto* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline CudaComputeCapabilityProto* New() const final {
    return CreateMaybeMessage<CudaComputeCapabilityProto>(nullptr);
  }

  CudaComputeCapabilityProto* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<CudaComputeCapabilityProto>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const CudaComputeCapabilityProto& from);
  void MergeFrom(const CudaComputeCapabilityProto& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(CudaComputeCapabilityProto* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "stream_executor.CudaComputeCapabilityProto";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kMajorFieldNumber = 1,
    kMinorFieldNumber = 2,
  };
  // int32 major = 1;
  void clear_major();
  ::PROTOBUF_NAMESPACE_ID::int32 major() const;
  void set_major(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 minor = 2;
  void clear_minor();
  ::PROTOBUF_NAMESPACE_ID::int32 minor() const;
  void set_minor(::PROTOBUF_NAMESPACE_ID::int32 value);

  // @@protoc_insertion_point(class_scope:stream_executor.CudaComputeCapabilityProto)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::int32 major_;
  ::PROTOBUF_NAMESPACE_ID::int32 minor_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto;
};
// -------------------------------------------------------------------

class RocmComputeCapabilityProto :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:stream_executor.RocmComputeCapabilityProto) */ {
 public:
  RocmComputeCapabilityProto();
  virtual ~RocmComputeCapabilityProto();

  RocmComputeCapabilityProto(const RocmComputeCapabilityProto& from);
  RocmComputeCapabilityProto(RocmComputeCapabilityProto&& from) noexcept
    : RocmComputeCapabilityProto() {
    *this = ::std::move(from);
  }

  inline RocmComputeCapabilityProto& operator=(const RocmComputeCapabilityProto& from) {
    CopyFrom(from);
    return *this;
  }
  inline RocmComputeCapabilityProto& operator=(RocmComputeCapabilityProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const RocmComputeCapabilityProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RocmComputeCapabilityProto* internal_default_instance() {
    return reinterpret_cast<const RocmComputeCapabilityProto*>(
               &_RocmComputeCapabilityProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(RocmComputeCapabilityProto& a, RocmComputeCapabilityProto& b) {
    a.Swap(&b);
  }
  inline void Swap(RocmComputeCapabilityProto* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline RocmComputeCapabilityProto* New() const final {
    return CreateMaybeMessage<RocmComputeCapabilityProto>(nullptr);
  }

  RocmComputeCapabilityProto* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<RocmComputeCapabilityProto>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const RocmComputeCapabilityProto& from);
  void MergeFrom(const RocmComputeCapabilityProto& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RocmComputeCapabilityProto* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "stream_executor.RocmComputeCapabilityProto";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kGcnArchNameFieldNumber = 1,
  };
  // string gcn_arch_name = 1;
  void clear_gcn_arch_name();
  const std::string& gcn_arch_name() const;
  void set_gcn_arch_name(const std::string& value);
  void set_gcn_arch_name(std::string&& value);
  void set_gcn_arch_name(const char* value);
  void set_gcn_arch_name(const char* value, size_t size);
  std::string* mutable_gcn_arch_name();
  std::string* release_gcn_arch_name();
  void set_allocated_gcn_arch_name(std::string* gcn_arch_name);

  // @@protoc_insertion_point(class_scope:stream_executor.RocmComputeCapabilityProto)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr gcn_arch_name_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto;
};
// -------------------------------------------------------------------

class GpuDeviceInfoProto :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:stream_executor.GpuDeviceInfoProto) */ {
 public:
  GpuDeviceInfoProto();
  virtual ~GpuDeviceInfoProto();

  GpuDeviceInfoProto(const GpuDeviceInfoProto& from);
  GpuDeviceInfoProto(GpuDeviceInfoProto&& from) noexcept
    : GpuDeviceInfoProto() {
    *this = ::std::move(from);
  }

  inline GpuDeviceInfoProto& operator=(const GpuDeviceInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  inline GpuDeviceInfoProto& operator=(GpuDeviceInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const GpuDeviceInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const GpuDeviceInfoProto* internal_default_instance() {
    return reinterpret_cast<const GpuDeviceInfoProto*>(
               &_GpuDeviceInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  friend void swap(GpuDeviceInfoProto& a, GpuDeviceInfoProto& b) {
    a.Swap(&b);
  }
  inline void Swap(GpuDeviceInfoProto* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline GpuDeviceInfoProto* New() const final {
    return CreateMaybeMessage<GpuDeviceInfoProto>(nullptr);
  }

  GpuDeviceInfoProto* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<GpuDeviceInfoProto>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const GpuDeviceInfoProto& from);
  void MergeFrom(const GpuDeviceInfoProto& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(GpuDeviceInfoProto* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "stream_executor.GpuDeviceInfoProto";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kThreadsPerBlockLimitFieldNumber = 1,
    kThreadsPerWarpFieldNumber = 2,
    kSharedMemoryPerBlockFieldNumber = 3,
    kSharedMemoryPerCoreFieldNumber = 4,
    kThreadsPerCoreLimitFieldNumber = 5,
    kCoreCountFieldNumber = 6,
    kFpusPerCoreFieldNumber = 7,
    kBlockDimLimitXFieldNumber = 8,
    kBlockDimLimitYFieldNumber = 9,
    kMemoryBandwidthFieldNumber = 11,
    kBlockDimLimitZFieldNumber = 10,
    kClockRateGhzFieldNumber = 13,
    kL2CacheSizeFieldNumber = 12,
    kDeviceMemorySizeFieldNumber = 14,
  };
  // int32 threads_per_block_limit = 1;
  void clear_threads_per_block_limit();
  ::PROTOBUF_NAMESPACE_ID::int32 threads_per_block_limit() const;
  void set_threads_per_block_limit(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 threads_per_warp = 2;
  void clear_threads_per_warp();
  ::PROTOBUF_NAMESPACE_ID::int32 threads_per_warp() const;
  void set_threads_per_warp(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 shared_memory_per_block = 3;
  void clear_shared_memory_per_block();
  ::PROTOBUF_NAMESPACE_ID::int32 shared_memory_per_block() const;
  void set_shared_memory_per_block(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 shared_memory_per_core = 4;
  void clear_shared_memory_per_core();
  ::PROTOBUF_NAMESPACE_ID::int32 shared_memory_per_core() const;
  void set_shared_memory_per_core(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 threads_per_core_limit = 5;
  void clear_threads_per_core_limit();
  ::PROTOBUF_NAMESPACE_ID::int32 threads_per_core_limit() const;
  void set_threads_per_core_limit(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 core_count = 6;
  void clear_core_count();
  ::PROTOBUF_NAMESPACE_ID::int32 core_count() const;
  void set_core_count(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int64 fpus_per_core = 7;
  void clear_fpus_per_core();
  ::PROTOBUF_NAMESPACE_ID::int64 fpus_per_core() const;
  void set_fpus_per_core(::PROTOBUF_NAMESPACE_ID::int64 value);

  // int32 block_dim_limit_x = 8;
  void clear_block_dim_limit_x();
  ::PROTOBUF_NAMESPACE_ID::int32 block_dim_limit_x() const;
  void set_block_dim_limit_x(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 block_dim_limit_y = 9;
  void clear_block_dim_limit_y();
  ::PROTOBUF_NAMESPACE_ID::int32 block_dim_limit_y() const;
  void set_block_dim_limit_y(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int64 memory_bandwidth = 11;
  void clear_memory_bandwidth();
  ::PROTOBUF_NAMESPACE_ID::int64 memory_bandwidth() const;
  void set_memory_bandwidth(::PROTOBUF_NAMESPACE_ID::int64 value);

  // int32 block_dim_limit_z = 10;
  void clear_block_dim_limit_z();
  ::PROTOBUF_NAMESPACE_ID::int32 block_dim_limit_z() const;
  void set_block_dim_limit_z(::PROTOBUF_NAMESPACE_ID::int32 value);

  // float clock_rate_ghz = 13;
  void clear_clock_rate_ghz();
  float clock_rate_ghz() const;
  void set_clock_rate_ghz(float value);

  // int64 l2_cache_size = 12;
  void clear_l2_cache_size();
  ::PROTOBUF_NAMESPACE_ID::int64 l2_cache_size() const;
  void set_l2_cache_size(::PROTOBUF_NAMESPACE_ID::int64 value);

  // int64 device_memory_size = 14;
  void clear_device_memory_size();
  ::PROTOBUF_NAMESPACE_ID::int64 device_memory_size() const;
  void set_device_memory_size(::PROTOBUF_NAMESPACE_ID::int64 value);

  // @@protoc_insertion_point(class_scope:stream_executor.GpuDeviceInfoProto)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::int32 threads_per_block_limit_;
  ::PROTOBUF_NAMESPACE_ID::int32 threads_per_warp_;
  ::PROTOBUF_NAMESPACE_ID::int32 shared_memory_per_block_;
  ::PROTOBUF_NAMESPACE_ID::int32 shared_memory_per_core_;
  ::PROTOBUF_NAMESPACE_ID::int32 threads_per_core_limit_;
  ::PROTOBUF_NAMESPACE_ID::int32 core_count_;
  ::PROTOBUF_NAMESPACE_ID::int64 fpus_per_core_;
  ::PROTOBUF_NAMESPACE_ID::int32 block_dim_limit_x_;
  ::PROTOBUF_NAMESPACE_ID::int32 block_dim_limit_y_;
  ::PROTOBUF_NAMESPACE_ID::int64 memory_bandwidth_;
  ::PROTOBUF_NAMESPACE_ID::int32 block_dim_limit_z_;
  float clock_rate_ghz_;
  ::PROTOBUF_NAMESPACE_ID::int64 l2_cache_size_;
  ::PROTOBUF_NAMESPACE_ID::int64 device_memory_size_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto;
};
// -------------------------------------------------------------------

class DnnVersionInfoProto :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:stream_executor.DnnVersionInfoProto) */ {
 public:
  DnnVersionInfoProto();
  virtual ~DnnVersionInfoProto();

  DnnVersionInfoProto(const DnnVersionInfoProto& from);
  DnnVersionInfoProto(DnnVersionInfoProto&& from) noexcept
    : DnnVersionInfoProto() {
    *this = ::std::move(from);
  }

  inline DnnVersionInfoProto& operator=(const DnnVersionInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  inline DnnVersionInfoProto& operator=(DnnVersionInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const DnnVersionInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DnnVersionInfoProto* internal_default_instance() {
    return reinterpret_cast<const DnnVersionInfoProto*>(
               &_DnnVersionInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  friend void swap(DnnVersionInfoProto& a, DnnVersionInfoProto& b) {
    a.Swap(&b);
  }
  inline void Swap(DnnVersionInfoProto* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline DnnVersionInfoProto* New() const final {
    return CreateMaybeMessage<DnnVersionInfoProto>(nullptr);
  }

  DnnVersionInfoProto* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<DnnVersionInfoProto>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const DnnVersionInfoProto& from);
  void MergeFrom(const DnnVersionInfoProto& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DnnVersionInfoProto* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "stream_executor.DnnVersionInfoProto";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kMajorFieldNumber = 1,
    kMinorFieldNumber = 2,
    kPatchFieldNumber = 3,
  };
  // int32 major = 1;
  void clear_major();
  ::PROTOBUF_NAMESPACE_ID::int32 major() const;
  void set_major(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 minor = 2;
  void clear_minor();
  ::PROTOBUF_NAMESPACE_ID::int32 minor() const;
  void set_minor(::PROTOBUF_NAMESPACE_ID::int32 value);

  // int32 patch = 3;
  void clear_patch();
  ::PROTOBUF_NAMESPACE_ID::int32 patch() const;
  void set_patch(::PROTOBUF_NAMESPACE_ID::int32 value);

  // @@protoc_insertion_point(class_scope:stream_executor.DnnVersionInfoProto)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::int32 major_;
  ::PROTOBUF_NAMESPACE_ID::int32 minor_;
  ::PROTOBUF_NAMESPACE_ID::int32 patch_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto;
};
// -------------------------------------------------------------------

class GpuTargetConfigProto :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:stream_executor.GpuTargetConfigProto) */ {
 public:
  GpuTargetConfigProto();
  virtual ~GpuTargetConfigProto();

  GpuTargetConfigProto(const GpuTargetConfigProto& from);
  GpuTargetConfigProto(GpuTargetConfigProto&& from) noexcept
    : GpuTargetConfigProto() {
    *this = ::std::move(from);
  }

  inline GpuTargetConfigProto& operator=(const GpuTargetConfigProto& from) {
    CopyFrom(from);
    return *this;
  }
  inline GpuTargetConfigProto& operator=(GpuTargetConfigProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const GpuTargetConfigProto& default_instance();

  enum ComputeCapabilityCase {
    kCudaComputeCapability = 2,
    kRocmComputeCapability = 3,
    COMPUTE_CAPABILITY_NOT_SET = 0,
  };

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const GpuTargetConfigProto* internal_default_instance() {
    return reinterpret_cast<const GpuTargetConfigProto*>(
               &_GpuTargetConfigProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  friend void swap(GpuTargetConfigProto& a, GpuTargetConfigProto& b) {
    a.Swap(&b);
  }
  inline void Swap(GpuTargetConfigProto* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline GpuTargetConfigProto* New() const final {
    return CreateMaybeMessage<GpuTargetConfigProto>(nullptr);
  }

  GpuTargetConfigProto* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<GpuTargetConfigProto>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const GpuTargetConfigProto& from);
  void MergeFrom(const GpuTargetConfigProto& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(GpuTargetConfigProto* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "stream_executor.GpuTargetConfigProto";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kPlatformNameFieldNumber = 4,
    kDeviceDescriptionStrFieldNumber = 7,
    kGpuDeviceInfoFieldNumber = 1,
    kDnnVersionInfoFieldNumber = 5,
    kAutotuneResultsFieldNumber = 6,
    kCudaComputeCapabilityFieldNumber = 2,
    kRocmComputeCapabilityFieldNumber = 3,
  };
  // string platform_name = 4;
  void clear_platform_name();
  const std::string& platform_name() const;
  void set_platform_name(const std::string& value);
  void set_platform_name(std::string&& value);
  void set_platform_name(const char* value);
  void set_platform_name(const char* value, size_t size);
  std::string* mutable_platform_name();
  std::string* release_platform_name();
  void set_allocated_platform_name(std::string* platform_name);

  // string device_description_str = 7;
  void clear_device_description_str();
  const std::string& device_description_str() const;
  void set_device_description_str(const std::string& value);
  void set_device_description_str(std::string&& value);
  void set_device_description_str(const char* value);
  void set_device_description_str(const char* value, size_t size);
  std::string* mutable_device_description_str();
  std::string* release_device_description_str();
  void set_allocated_device_description_str(std::string* device_description_str);

  // .stream_executor.GpuDeviceInfoProto gpu_device_info = 1;
  bool has_gpu_device_info() const;
  void clear_gpu_device_info();
  const ::stream_executor::GpuDeviceInfoProto& gpu_device_info() const;
  ::stream_executor::GpuDeviceInfoProto* release_gpu_device_info();
  ::stream_executor::GpuDeviceInfoProto* mutable_gpu_device_info();
  void set_allocated_gpu_device_info(::stream_executor::GpuDeviceInfoProto* gpu_device_info);

  // .stream_executor.DnnVersionInfoProto dnn_version_info = 5;
  bool has_dnn_version_info() const;
  void clear_dnn_version_info();
  const ::stream_executor::DnnVersionInfoProto& dnn_version_info() const;
  ::stream_executor::DnnVersionInfoProto* release_dnn_version_info();
  ::stream_executor::DnnVersionInfoProto* mutable_dnn_version_info();
  void set_allocated_dnn_version_info(::stream_executor::DnnVersionInfoProto* dnn_version_info);

  // .xla.AutotuneResults autotune_results = 6;
  bool has_autotune_results() const;
  void clear_autotune_results();
  const ::xla::AutotuneResults& autotune_results() const;
  ::xla::AutotuneResults* release_autotune_results();
  ::xla::AutotuneResults* mutable_autotune_results();
  void set_allocated_autotune_results(::xla::AutotuneResults* autotune_results);

  // .stream_executor.CudaComputeCapabilityProto cuda_compute_capability = 2;
  bool has_cuda_compute_capability() const;
  void clear_cuda_compute_capability();
  const ::stream_executor::CudaComputeCapabilityProto& cuda_compute_capability() const;
  ::stream_executor::CudaComputeCapabilityProto* release_cuda_compute_capability();
  ::stream_executor::CudaComputeCapabilityProto* mutable_cuda_compute_capability();
  void set_allocated_cuda_compute_capability(::stream_executor::CudaComputeCapabilityProto* cuda_compute_capability);

  // .stream_executor.RocmComputeCapabilityProto rocm_compute_capability = 3;
  bool has_rocm_compute_capability() const;
  void clear_rocm_compute_capability();
  const ::stream_executor::RocmComputeCapabilityProto& rocm_compute_capability() const;
  ::stream_executor::RocmComputeCapabilityProto* release_rocm_compute_capability();
  ::stream_executor::RocmComputeCapabilityProto* mutable_rocm_compute_capability();
  void set_allocated_rocm_compute_capability(::stream_executor::RocmComputeCapabilityProto* rocm_compute_capability);

  void clear_compute_capability();
  ComputeCapabilityCase compute_capability_case() const;
  // @@protoc_insertion_point(class_scope:stream_executor.GpuTargetConfigProto)
 private:
  class _Internal;
  void set_has_cuda_compute_capability();
  void set_has_rocm_compute_capability();

  inline bool has_compute_capability() const;
  inline void clear_has_compute_capability();

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr platform_name_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr device_description_str_;
  ::stream_executor::GpuDeviceInfoProto* gpu_device_info_;
  ::stream_executor::DnnVersionInfoProto* dnn_version_info_;
  ::xla::AutotuneResults* autotune_results_;
  union ComputeCapabilityUnion {
    ComputeCapabilityUnion() {}
    ::stream_executor::CudaComputeCapabilityProto* cuda_compute_capability_;
    ::stream_executor::RocmComputeCapabilityProto* rocm_compute_capability_;
  } compute_capability_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  ::PROTOBUF_NAMESPACE_ID::uint32 _oneof_case_[1];

  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// CudaComputeCapabilityProto

// int32 major = 1;
inline void CudaComputeCapabilityProto::clear_major() {
  major_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 CudaComputeCapabilityProto::major() const {
  // @@protoc_insertion_point(field_get:stream_executor.CudaComputeCapabilityProto.major)
  return major_;
}
inline void CudaComputeCapabilityProto::set_major(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  major_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.CudaComputeCapabilityProto.major)
}

// int32 minor = 2;
inline void CudaComputeCapabilityProto::clear_minor() {
  minor_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 CudaComputeCapabilityProto::minor() const {
  // @@protoc_insertion_point(field_get:stream_executor.CudaComputeCapabilityProto.minor)
  return minor_;
}
inline void CudaComputeCapabilityProto::set_minor(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  minor_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.CudaComputeCapabilityProto.minor)
}

// -------------------------------------------------------------------

// RocmComputeCapabilityProto

// string gcn_arch_name = 1;
inline void RocmComputeCapabilityProto::clear_gcn_arch_name() {
  gcn_arch_name_.ClearToEmptyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline const std::string& RocmComputeCapabilityProto::gcn_arch_name() const {
  // @@protoc_insertion_point(field_get:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
  return gcn_arch_name_.GetNoArena();
}
inline void RocmComputeCapabilityProto::set_gcn_arch_name(const std::string& value) {
  
  gcn_arch_name_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
}
inline void RocmComputeCapabilityProto::set_gcn_arch_name(std::string&& value) {
  
  gcn_arch_name_.SetNoArena(
    &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
}
inline void RocmComputeCapabilityProto::set_gcn_arch_name(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  gcn_arch_name_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
}
inline void RocmComputeCapabilityProto::set_gcn_arch_name(const char* value, size_t size) {
  
  gcn_arch_name_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
}
inline std::string* RocmComputeCapabilityProto::mutable_gcn_arch_name() {
  
  // @@protoc_insertion_point(field_mutable:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
  return gcn_arch_name_.MutableNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline std::string* RocmComputeCapabilityProto::release_gcn_arch_name() {
  // @@protoc_insertion_point(field_release:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
  
  return gcn_arch_name_.ReleaseNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline void RocmComputeCapabilityProto::set_allocated_gcn_arch_name(std::string* gcn_arch_name) {
  if (gcn_arch_name != nullptr) {
    
  } else {
    
  }
  gcn_arch_name_.SetAllocatedNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), gcn_arch_name);
  // @@protoc_insertion_point(field_set_allocated:stream_executor.RocmComputeCapabilityProto.gcn_arch_name)
}

// -------------------------------------------------------------------

// GpuDeviceInfoProto

// int32 threads_per_block_limit = 1;
inline void GpuDeviceInfoProto::clear_threads_per_block_limit() {
  threads_per_block_limit_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::threads_per_block_limit() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.threads_per_block_limit)
  return threads_per_block_limit_;
}
inline void GpuDeviceInfoProto::set_threads_per_block_limit(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  threads_per_block_limit_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.threads_per_block_limit)
}

// int32 threads_per_warp = 2;
inline void GpuDeviceInfoProto::clear_threads_per_warp() {
  threads_per_warp_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::threads_per_warp() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.threads_per_warp)
  return threads_per_warp_;
}
inline void GpuDeviceInfoProto::set_threads_per_warp(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  threads_per_warp_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.threads_per_warp)
}

// int32 shared_memory_per_block = 3;
inline void GpuDeviceInfoProto::clear_shared_memory_per_block() {
  shared_memory_per_block_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::shared_memory_per_block() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.shared_memory_per_block)
  return shared_memory_per_block_;
}
inline void GpuDeviceInfoProto::set_shared_memory_per_block(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  shared_memory_per_block_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.shared_memory_per_block)
}

// int32 shared_memory_per_core = 4;
inline void GpuDeviceInfoProto::clear_shared_memory_per_core() {
  shared_memory_per_core_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::shared_memory_per_core() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.shared_memory_per_core)
  return shared_memory_per_core_;
}
inline void GpuDeviceInfoProto::set_shared_memory_per_core(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  shared_memory_per_core_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.shared_memory_per_core)
}

// int32 threads_per_core_limit = 5;
inline void GpuDeviceInfoProto::clear_threads_per_core_limit() {
  threads_per_core_limit_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::threads_per_core_limit() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.threads_per_core_limit)
  return threads_per_core_limit_;
}
inline void GpuDeviceInfoProto::set_threads_per_core_limit(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  threads_per_core_limit_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.threads_per_core_limit)
}

// int32 core_count = 6;
inline void GpuDeviceInfoProto::clear_core_count() {
  core_count_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::core_count() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.core_count)
  return core_count_;
}
inline void GpuDeviceInfoProto::set_core_count(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  core_count_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.core_count)
}

// int64 fpus_per_core = 7;
inline void GpuDeviceInfoProto::clear_fpus_per_core() {
  fpus_per_core_ = PROTOBUF_LONGLONG(0);
}
inline ::PROTOBUF_NAMESPACE_ID::int64 GpuDeviceInfoProto::fpus_per_core() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.fpus_per_core)
  return fpus_per_core_;
}
inline void GpuDeviceInfoProto::set_fpus_per_core(::PROTOBUF_NAMESPACE_ID::int64 value) {
  
  fpus_per_core_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.fpus_per_core)
}

// int32 block_dim_limit_x = 8;
inline void GpuDeviceInfoProto::clear_block_dim_limit_x() {
  block_dim_limit_x_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::block_dim_limit_x() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.block_dim_limit_x)
  return block_dim_limit_x_;
}
inline void GpuDeviceInfoProto::set_block_dim_limit_x(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  block_dim_limit_x_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.block_dim_limit_x)
}

// int32 block_dim_limit_y = 9;
inline void GpuDeviceInfoProto::clear_block_dim_limit_y() {
  block_dim_limit_y_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::block_dim_limit_y() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.block_dim_limit_y)
  return block_dim_limit_y_;
}
inline void GpuDeviceInfoProto::set_block_dim_limit_y(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  block_dim_limit_y_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.block_dim_limit_y)
}

// int32 block_dim_limit_z = 10;
inline void GpuDeviceInfoProto::clear_block_dim_limit_z() {
  block_dim_limit_z_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 GpuDeviceInfoProto::block_dim_limit_z() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.block_dim_limit_z)
  return block_dim_limit_z_;
}
inline void GpuDeviceInfoProto::set_block_dim_limit_z(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  block_dim_limit_z_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.block_dim_limit_z)
}

// int64 memory_bandwidth = 11;
inline void GpuDeviceInfoProto::clear_memory_bandwidth() {
  memory_bandwidth_ = PROTOBUF_LONGLONG(0);
}
inline ::PROTOBUF_NAMESPACE_ID::int64 GpuDeviceInfoProto::memory_bandwidth() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.memory_bandwidth)
  return memory_bandwidth_;
}
inline void GpuDeviceInfoProto::set_memory_bandwidth(::PROTOBUF_NAMESPACE_ID::int64 value) {
  
  memory_bandwidth_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.memory_bandwidth)
}

// int64 l2_cache_size = 12;
inline void GpuDeviceInfoProto::clear_l2_cache_size() {
  l2_cache_size_ = PROTOBUF_LONGLONG(0);
}
inline ::PROTOBUF_NAMESPACE_ID::int64 GpuDeviceInfoProto::l2_cache_size() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.l2_cache_size)
  return l2_cache_size_;
}
inline void GpuDeviceInfoProto::set_l2_cache_size(::PROTOBUF_NAMESPACE_ID::int64 value) {
  
  l2_cache_size_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.l2_cache_size)
}

// float clock_rate_ghz = 13;
inline void GpuDeviceInfoProto::clear_clock_rate_ghz() {
  clock_rate_ghz_ = 0;
}
inline float GpuDeviceInfoProto::clock_rate_ghz() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.clock_rate_ghz)
  return clock_rate_ghz_;
}
inline void GpuDeviceInfoProto::set_clock_rate_ghz(float value) {
  
  clock_rate_ghz_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.clock_rate_ghz)
}

// int64 device_memory_size = 14;
inline void GpuDeviceInfoProto::clear_device_memory_size() {
  device_memory_size_ = PROTOBUF_LONGLONG(0);
}
inline ::PROTOBUF_NAMESPACE_ID::int64 GpuDeviceInfoProto::device_memory_size() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuDeviceInfoProto.device_memory_size)
  return device_memory_size_;
}
inline void GpuDeviceInfoProto::set_device_memory_size(::PROTOBUF_NAMESPACE_ID::int64 value) {
  
  device_memory_size_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.GpuDeviceInfoProto.device_memory_size)
}

// -------------------------------------------------------------------

// DnnVersionInfoProto

// int32 major = 1;
inline void DnnVersionInfoProto::clear_major() {
  major_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 DnnVersionInfoProto::major() const {
  // @@protoc_insertion_point(field_get:stream_executor.DnnVersionInfoProto.major)
  return major_;
}
inline void DnnVersionInfoProto::set_major(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  major_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.DnnVersionInfoProto.major)
}

// int32 minor = 2;
inline void DnnVersionInfoProto::clear_minor() {
  minor_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 DnnVersionInfoProto::minor() const {
  // @@protoc_insertion_point(field_get:stream_executor.DnnVersionInfoProto.minor)
  return minor_;
}
inline void DnnVersionInfoProto::set_minor(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  minor_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.DnnVersionInfoProto.minor)
}

// int32 patch = 3;
inline void DnnVersionInfoProto::clear_patch() {
  patch_ = 0;
}
inline ::PROTOBUF_NAMESPACE_ID::int32 DnnVersionInfoProto::patch() const {
  // @@protoc_insertion_point(field_get:stream_executor.DnnVersionInfoProto.patch)
  return patch_;
}
inline void DnnVersionInfoProto::set_patch(::PROTOBUF_NAMESPACE_ID::int32 value) {
  
  patch_ = value;
  // @@protoc_insertion_point(field_set:stream_executor.DnnVersionInfoProto.patch)
}

// -------------------------------------------------------------------

// GpuTargetConfigProto

// .stream_executor.GpuDeviceInfoProto gpu_device_info = 1;
inline bool GpuTargetConfigProto::has_gpu_device_info() const {
  return this != internal_default_instance() && gpu_device_info_ != nullptr;
}
inline void GpuTargetConfigProto::clear_gpu_device_info() {
  if (GetArenaNoVirtual() == nullptr && gpu_device_info_ != nullptr) {
    delete gpu_device_info_;
  }
  gpu_device_info_ = nullptr;
}
inline const ::stream_executor::GpuDeviceInfoProto& GpuTargetConfigProto::gpu_device_info() const {
  const ::stream_executor::GpuDeviceInfoProto* p = gpu_device_info_;
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.gpu_device_info)
  return p != nullptr ? *p : *reinterpret_cast<const ::stream_executor::GpuDeviceInfoProto*>(
      &::stream_executor::_GpuDeviceInfoProto_default_instance_);
}
inline ::stream_executor::GpuDeviceInfoProto* GpuTargetConfigProto::release_gpu_device_info() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.gpu_device_info)
  
  ::stream_executor::GpuDeviceInfoProto* temp = gpu_device_info_;
  gpu_device_info_ = nullptr;
  return temp;
}
inline ::stream_executor::GpuDeviceInfoProto* GpuTargetConfigProto::mutable_gpu_device_info() {
  
  if (gpu_device_info_ == nullptr) {
    auto* p = CreateMaybeMessage<::stream_executor::GpuDeviceInfoProto>(GetArenaNoVirtual());
    gpu_device_info_ = p;
  }
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.gpu_device_info)
  return gpu_device_info_;
}
inline void GpuTargetConfigProto::set_allocated_gpu_device_info(::stream_executor::GpuDeviceInfoProto* gpu_device_info) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete gpu_device_info_;
  }
  if (gpu_device_info) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = nullptr;
    if (message_arena != submessage_arena) {
      gpu_device_info = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, gpu_device_info, submessage_arena);
    }
    
  } else {
    
  }
  gpu_device_info_ = gpu_device_info;
  // @@protoc_insertion_point(field_set_allocated:stream_executor.GpuTargetConfigProto.gpu_device_info)
}

// .stream_executor.CudaComputeCapabilityProto cuda_compute_capability = 2;
inline bool GpuTargetConfigProto::has_cuda_compute_capability() const {
  return compute_capability_case() == kCudaComputeCapability;
}
inline void GpuTargetConfigProto::set_has_cuda_compute_capability() {
  _oneof_case_[0] = kCudaComputeCapability;
}
inline void GpuTargetConfigProto::clear_cuda_compute_capability() {
  if (has_cuda_compute_capability()) {
    delete compute_capability_.cuda_compute_capability_;
    clear_has_compute_capability();
  }
}
inline ::stream_executor::CudaComputeCapabilityProto* GpuTargetConfigProto::release_cuda_compute_capability() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.cuda_compute_capability)
  if (has_cuda_compute_capability()) {
    clear_has_compute_capability();
      ::stream_executor::CudaComputeCapabilityProto* temp = compute_capability_.cuda_compute_capability_;
    compute_capability_.cuda_compute_capability_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::stream_executor::CudaComputeCapabilityProto& GpuTargetConfigProto::cuda_compute_capability() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.cuda_compute_capability)
  return has_cuda_compute_capability()
      ? *compute_capability_.cuda_compute_capability_
      : *reinterpret_cast< ::stream_executor::CudaComputeCapabilityProto*>(&::stream_executor::_CudaComputeCapabilityProto_default_instance_);
}
inline ::stream_executor::CudaComputeCapabilityProto* GpuTargetConfigProto::mutable_cuda_compute_capability() {
  if (!has_cuda_compute_capability()) {
    clear_compute_capability();
    set_has_cuda_compute_capability();
    compute_capability_.cuda_compute_capability_ = CreateMaybeMessage< ::stream_executor::CudaComputeCapabilityProto >(
        GetArenaNoVirtual());
  }
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.cuda_compute_capability)
  return compute_capability_.cuda_compute_capability_;
}

// .stream_executor.RocmComputeCapabilityProto rocm_compute_capability = 3;
inline bool GpuTargetConfigProto::has_rocm_compute_capability() const {
  return compute_capability_case() == kRocmComputeCapability;
}
inline void GpuTargetConfigProto::set_has_rocm_compute_capability() {
  _oneof_case_[0] = kRocmComputeCapability;
}
inline void GpuTargetConfigProto::clear_rocm_compute_capability() {
  if (has_rocm_compute_capability()) {
    delete compute_capability_.rocm_compute_capability_;
    clear_has_compute_capability();
  }
}
inline ::stream_executor::RocmComputeCapabilityProto* GpuTargetConfigProto::release_rocm_compute_capability() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.rocm_compute_capability)
  if (has_rocm_compute_capability()) {
    clear_has_compute_capability();
      ::stream_executor::RocmComputeCapabilityProto* temp = compute_capability_.rocm_compute_capability_;
    compute_capability_.rocm_compute_capability_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::stream_executor::RocmComputeCapabilityProto& GpuTargetConfigProto::rocm_compute_capability() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.rocm_compute_capability)
  return has_rocm_compute_capability()
      ? *compute_capability_.rocm_compute_capability_
      : *reinterpret_cast< ::stream_executor::RocmComputeCapabilityProto*>(&::stream_executor::_RocmComputeCapabilityProto_default_instance_);
}
inline ::stream_executor::RocmComputeCapabilityProto* GpuTargetConfigProto::mutable_rocm_compute_capability() {
  if (!has_rocm_compute_capability()) {
    clear_compute_capability();
    set_has_rocm_compute_capability();
    compute_capability_.rocm_compute_capability_ = CreateMaybeMessage< ::stream_executor::RocmComputeCapabilityProto >(
        GetArenaNoVirtual());
  }
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.rocm_compute_capability)
  return compute_capability_.rocm_compute_capability_;
}

// string platform_name = 4;
inline void GpuTargetConfigProto::clear_platform_name() {
  platform_name_.ClearToEmptyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline const std::string& GpuTargetConfigProto::platform_name() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.platform_name)
  return platform_name_.GetNoArena();
}
inline void GpuTargetConfigProto::set_platform_name(const std::string& value) {
  
  platform_name_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:stream_executor.GpuTargetConfigProto.platform_name)
}
inline void GpuTargetConfigProto::set_platform_name(std::string&& value) {
  
  platform_name_.SetNoArena(
    &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:stream_executor.GpuTargetConfigProto.platform_name)
}
inline void GpuTargetConfigProto::set_platform_name(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  platform_name_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:stream_executor.GpuTargetConfigProto.platform_name)
}
inline void GpuTargetConfigProto::set_platform_name(const char* value, size_t size) {
  
  platform_name_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:stream_executor.GpuTargetConfigProto.platform_name)
}
inline std::string* GpuTargetConfigProto::mutable_platform_name() {
  
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.platform_name)
  return platform_name_.MutableNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline std::string* GpuTargetConfigProto::release_platform_name() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.platform_name)
  
  return platform_name_.ReleaseNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline void GpuTargetConfigProto::set_allocated_platform_name(std::string* platform_name) {
  if (platform_name != nullptr) {
    
  } else {
    
  }
  platform_name_.SetAllocatedNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), platform_name);
  // @@protoc_insertion_point(field_set_allocated:stream_executor.GpuTargetConfigProto.platform_name)
}

// .stream_executor.DnnVersionInfoProto dnn_version_info = 5;
inline bool GpuTargetConfigProto::has_dnn_version_info() const {
  return this != internal_default_instance() && dnn_version_info_ != nullptr;
}
inline void GpuTargetConfigProto::clear_dnn_version_info() {
  if (GetArenaNoVirtual() == nullptr && dnn_version_info_ != nullptr) {
    delete dnn_version_info_;
  }
  dnn_version_info_ = nullptr;
}
inline const ::stream_executor::DnnVersionInfoProto& GpuTargetConfigProto::dnn_version_info() const {
  const ::stream_executor::DnnVersionInfoProto* p = dnn_version_info_;
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.dnn_version_info)
  return p != nullptr ? *p : *reinterpret_cast<const ::stream_executor::DnnVersionInfoProto*>(
      &::stream_executor::_DnnVersionInfoProto_default_instance_);
}
inline ::stream_executor::DnnVersionInfoProto* GpuTargetConfigProto::release_dnn_version_info() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.dnn_version_info)
  
  ::stream_executor::DnnVersionInfoProto* temp = dnn_version_info_;
  dnn_version_info_ = nullptr;
  return temp;
}
inline ::stream_executor::DnnVersionInfoProto* GpuTargetConfigProto::mutable_dnn_version_info() {
  
  if (dnn_version_info_ == nullptr) {
    auto* p = CreateMaybeMessage<::stream_executor::DnnVersionInfoProto>(GetArenaNoVirtual());
    dnn_version_info_ = p;
  }
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.dnn_version_info)
  return dnn_version_info_;
}
inline void GpuTargetConfigProto::set_allocated_dnn_version_info(::stream_executor::DnnVersionInfoProto* dnn_version_info) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete dnn_version_info_;
  }
  if (dnn_version_info) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = nullptr;
    if (message_arena != submessage_arena) {
      dnn_version_info = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, dnn_version_info, submessage_arena);
    }
    
  } else {
    
  }
  dnn_version_info_ = dnn_version_info;
  // @@protoc_insertion_point(field_set_allocated:stream_executor.GpuTargetConfigProto.dnn_version_info)
}

// .xla.AutotuneResults autotune_results = 6;
inline bool GpuTargetConfigProto::has_autotune_results() const {
  return this != internal_default_instance() && autotune_results_ != nullptr;
}
inline const ::xla::AutotuneResults& GpuTargetConfigProto::autotune_results() const {
  const ::xla::AutotuneResults* p = autotune_results_;
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.autotune_results)
  return p != nullptr ? *p : *reinterpret_cast<const ::xla::AutotuneResults*>(
      &::xla::_AutotuneResults_default_instance_);
}
inline ::xla::AutotuneResults* GpuTargetConfigProto::release_autotune_results() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.autotune_results)
  
  ::xla::AutotuneResults* temp = autotune_results_;
  autotune_results_ = nullptr;
  return temp;
}
inline ::xla::AutotuneResults* GpuTargetConfigProto::mutable_autotune_results() {
  
  if (autotune_results_ == nullptr) {
    auto* p = CreateMaybeMessage<::xla::AutotuneResults>(GetArenaNoVirtual());
    autotune_results_ = p;
  }
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.autotune_results)
  return autotune_results_;
}
inline void GpuTargetConfigProto::set_allocated_autotune_results(::xla::AutotuneResults* autotune_results) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(autotune_results_);
  }
  if (autotune_results) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = nullptr;
    if (message_arena != submessage_arena) {
      autotune_results = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, autotune_results, submessage_arena);
    }
    
  } else {
    
  }
  autotune_results_ = autotune_results;
  // @@protoc_insertion_point(field_set_allocated:stream_executor.GpuTargetConfigProto.autotune_results)
}

// string device_description_str = 7;
inline void GpuTargetConfigProto::clear_device_description_str() {
  device_description_str_.ClearToEmptyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline const std::string& GpuTargetConfigProto::device_description_str() const {
  // @@protoc_insertion_point(field_get:stream_executor.GpuTargetConfigProto.device_description_str)
  return device_description_str_.GetNoArena();
}
inline void GpuTargetConfigProto::set_device_description_str(const std::string& value) {
  
  device_description_str_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:stream_executor.GpuTargetConfigProto.device_description_str)
}
inline void GpuTargetConfigProto::set_device_description_str(std::string&& value) {
  
  device_description_str_.SetNoArena(
    &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:stream_executor.GpuTargetConfigProto.device_description_str)
}
inline void GpuTargetConfigProto::set_device_description_str(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  device_description_str_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:stream_executor.GpuTargetConfigProto.device_description_str)
}
inline void GpuTargetConfigProto::set_device_description_str(const char* value, size_t size) {
  
  device_description_str_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:stream_executor.GpuTargetConfigProto.device_description_str)
}
inline std::string* GpuTargetConfigProto::mutable_device_description_str() {
  
  // @@protoc_insertion_point(field_mutable:stream_executor.GpuTargetConfigProto.device_description_str)
  return device_description_str_.MutableNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline std::string* GpuTargetConfigProto::release_device_description_str() {
  // @@protoc_insertion_point(field_release:stream_executor.GpuTargetConfigProto.device_description_str)
  
  return device_description_str_.ReleaseNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline void GpuTargetConfigProto::set_allocated_device_description_str(std::string* device_description_str) {
  if (device_description_str != nullptr) {
    
  } else {
    
  }
  device_description_str_.SetAllocatedNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), device_description_str);
  // @@protoc_insertion_point(field_set_allocated:stream_executor.GpuTargetConfigProto.device_description_str)
}

inline bool GpuTargetConfigProto::has_compute_capability() const {
  return compute_capability_case() != COMPUTE_CAPABILITY_NOT_SET;
}
inline void GpuTargetConfigProto::clear_has_compute_capability() {
  _oneof_case_[0] = COMPUTE_CAPABILITY_NOT_SET;
}
inline GpuTargetConfigProto::ComputeCapabilityCase GpuTargetConfigProto::compute_capability_case() const {
  return GpuTargetConfigProto::ComputeCapabilityCase(_oneof_case_[0]);
}
#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace stream_executor

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdevice_5fdescription_2eproto
